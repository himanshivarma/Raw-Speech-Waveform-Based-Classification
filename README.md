# Pre-trained Self-supervised Speech Representations for Classification among Healthy Subjects and Patients with Amyotrophic Lateral Sclerosis and Parkinson’s Disease
Speech representations learned via self-supervised learning attain state-of-the-art performances at various tasks like automatic speech recognition, speaker verification etc. However, these features are not yet well explored for automatic diagnosis of amyotrophic lateral sclerosis (ALS) and Parkinson’s disease (PD). We propose to explore self-supervised speech representations obtained from different pre-trained models for ALS vs healthy control (HC), PD vs HC, and ALS vs PD classifications. Convolutional neural networks with long short term memories are used as the classifiers. Experiments with 80 ALS, 80 PD, and 80 HC subjects indicate that the representations obtained from HuBERT and Wav2Vec models, both of which use contrastive losses, are better suited for our tasks. Considering all classification tasks at hand, HuBERT features achieve the highest average accuracy outperforming baseline mel-frequency cepstral coefficients (MFCC) and pitch features by 7.61% and 15.02%, respectively.
